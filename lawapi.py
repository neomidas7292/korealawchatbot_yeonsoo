import requests
import xml.etree.ElementTree as ET
import json
import os
import logging
import re
from typing import Optional, Tuple, List, Dict
import streamlit as st

class LawAPI:
    def __init__(self, oc: str):
        """ë²•ë ¹ API í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            oc: API í‚¤
        """
        self.oc = oc
        self.base_url = "http://www.law.go.kr/DRF/"
    
    def search_law_id(self, query: str) -> Tuple[Optional[str], Optional[str]]:
        """ë²•ë ¹ëª…ìœ¼ë¡œ ê²€ìƒ‰í•´ì„œ ì²« ë²ˆì§¸ ë²•ë ¹ì˜ IDë¥¼ ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰í•  ë²•ë ¹ëª…
            
        Returns:
            Tuple[ë²•ë ¹ID, ë²•ë ¹ëª…í•œê¸€] ë˜ëŠ” (None, None)
        """
        url = f"{self.base_url}lawSearch.do"
        params = {
            "OC": self.oc,
            "target": "law",
            "type": "XML",
            "query": query
        }

        response = None
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()

            root = ET.fromstring(response.content)
            law = root.find("law")

            if law is None:
                return None, None

            return law.findtext("ë²•ë ¹ID"), law.findtext("ë²•ë ¹ëª…í•œê¸€")

        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì„œë²„ì—ì„œ ë°›ì€ ì‹¤ì œ ì‘ë‹µì„ ì¶œë ¥ (ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
            if response is not None and hasattr(response, "text"):
                print("===== API ì„œë²„ ì‹¤ì œ ì‘ë‹µ ë‚´ìš© =====")
                print(response.text)
                print("===================================")
            logging.exception("ë²•ë ¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            st.error(f"ë²•ë ¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None
    
    def get_law_json(self, law_id: str) -> Optional[Dict]:
        """ë²•ë ¹ IDë¡œ ë²•ë ¹ ë°ì´í„° ì¡°íšŒ
        
        Args:
            law_id: ë²•ë ¹ ID
            
        Returns:
            ë²•ë ¹ ë°ì´í„° ë˜ëŠ” None
        """
        url = f"{self.base_url}lawService.do"
        params = {
            "OC": self.oc,
            "target": "law",
            "type": "JSON",
            "ID": law_id
        }
        
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        
        except Exception as e:
            st.error(f"ë²•ë ¹ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def clean_law_data(self, law_data: Dict) -> Dict:
        """í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì •ì œëœ ë°ì´í„° ë°˜í™˜ (ì¡° ë‹¨ìœ„ë¡œ ê³ ì •)
        
        Args:
            law_data: ë²•ë ¹ ì›ë³¸ ë°ì´í„°
            
        Returns:
            ì •ì œëœ ë²•ë ¹ ë°ì´í„°
        """
        # ê¸°ë³¸ì •ë³´ì—ì„œ ë²•ë ¹IDì™€ ë²•ë ¹ëª… ì¶”ì¶œ
        basic_info = law_data.get("ë²•ë ¹", {}).get("ê¸°ë³¸ì •ë³´", {})
        cleaned_data = {
            "ë²•ë ¹ID": basic_info.get("ë²•ë ¹ID"),
            "ë²•ë ¹ëª…_í•œê¸€": basic_info.get("ë²•ë ¹ëª…_í•œê¸€"),
            "ì¡°ë¬¸": []
        }
        
        # ì¡°ë¬¸ ë°ì´í„° ì¶”ì¶œ
        law_content = law_data.get("ë²•ë ¹", {})
        if "ì¡°ë¬¸" in law_content:
            articles = law_content["ì¡°ë¬¸"]
            if "ì¡°ë¬¸ë‹¨ìœ„" in articles:
                # ì¡°ë¬¸ë‹¨ìœ„ê°€ ë‹¨ì¼ í•­ëª©ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ê¸°
                if isinstance(articles["ì¡°ë¬¸ë‹¨ìœ„"], dict):
                    articles_list = [articles["ì¡°ë¬¸ë‹¨ìœ„"]]
                else:
                    articles_list = articles["ì¡°ë¬¸ë‹¨ìœ„"]

                for article in articles_list:
                    full_content = article.get("ì¡°ë¬¸ë‚´ìš©", "")
                    
                    # í•­ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì¡°ë¬¸ë‚´ìš©ì— ì¶”ê°€
                    if "í•­" in article:
                        full_content += self._extract_all_content_from_items(article["í•­"])
                    
                    article_data = {
                        "ì¡°ë¬¸ë²ˆí˜¸": article.get("ì¡°ë¬¸ë²ˆí˜¸"),
                        "ì¡°ë¬¸ì œëª©": article.get("ì¡°ë¬¸ì œëª©"),
                        "ì¡°ë¬¸ë‚´ìš©": full_content.strip()  # ê³µë°± ì œê±°
                    }
                    cleaned_data["ì¡°ë¬¸"].append(article_data)
        
        return cleaned_data
    
    def _extract_all_content_from_items(self, items) -> str:
        """í•­ ë°ì´í„°ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œ"""
        content = ""
        
        # itemsê°€ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ì¸ ê²½ìš°ì—ë„ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
        if isinstance(items, dict):
            items = [items]  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜ë³µë¬¸ ì²˜ë¦¬

        if isinstance(items, list):
            for item in items:
                hang_content = item.get("í•­ë‚´ìš©")
                if hang_content:
                    # í•­ë‚´ìš©ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(hang_content, list):
                        content += "\n" + " ".join(str(i) for i in hang_content)
                    else:
                        content += "\n" + str(hang_content)
                
                if "í˜¸" in item:
                    content += self._extract_all_content_from_subitems(item["í˜¸"])
        
        return content
    
    def _extract_all_content_from_subitems(self, subitems) -> str:
        """í˜¸ ë°ì´í„°ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œ"""
        content = ""
        
        # subitemsê°€ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ì¸ ê²½ìš°ì—ë„ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
        if isinstance(subitems, dict):
            subitems = [subitems]  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜ë³µë¬¸ ì²˜ë¦¬

        if isinstance(subitems, list):
            for subitem in subitems:
                ho_content = subitem.get("í˜¸ë‚´ìš©")
                if ho_content:
                    # í˜¸ë‚´ìš©ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(ho_content, list):
                        content += "\n" + " ".join(str(i) for i in ho_content)
                    else:
                        content += "\n" + str(ho_content)
        
        return content
    
    def download_law_as_json(self, query: str) -> Optional[Dict]:
        """ë²•ë ¹ì„ ê²€ìƒ‰í•˜ì—¬ JSON ë°ì´í„°ë¡œ ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰í•  ë²•ë ¹ëª…
            
        Returns:
            ì •ì œëœ ë²•ë ¹ ë°ì´í„° ë˜ëŠ” None
        """
        # 1. ë²•ë ¹ ID ê²€ìƒ‰
        law_id, law_name = self.search_law_id(query)
        if not law_id:
            return None
        
        # 2. ë²•ë ¹ ë°ì´í„° ì¡°íšŒ
        law_data = self.get_law_json(law_id)
        if not law_data:
            return None
        
        # 3. ë°ì´í„° ì •ì œ
        cleaned_data = self.clean_law_data(law_data)
        
        return cleaned_data
    
    def save_law_json_file(self, query: str, filename: str) -> bool:
        """ë²•ë ¹ì„ ê²€ìƒ‰í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            query: ê²€ìƒ‰í•  ë²•ë ¹ëª…
            filename: ì €ì¥í•  íŒŒì¼ëª…
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        cleaned_data = self.download_law_as_json(query)
        if not cleaned_data:
            return False
        
        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(cleaned_data, f, ensure_ascii=False, indent=4)
            return True
        except Exception as e:
            st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def batch_download_laws(self, law_names: List[str]) -> Dict[str, Dict]:
        """ì—¬ëŸ¬ ë²•ë ¹ì„ ì¼ê´„ ë‹¤ìš´ë¡œë“œ
        
        Args:
            law_names: ë‹¤ìš´ë¡œë“œí•  ë²•ë ¹ëª… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            {ë²•ë ¹ëª…: ë²•ë ¹ë°ì´í„°} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        for law_name in law_names:
            st.info(f"'{law_name}' ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            cleaned_data = self.download_law_as_json(law_name)
            if cleaned_data:
                results[law_name] = cleaned_data
                st.success(f"âœ… '{law_name}' ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({len(cleaned_data.get('ì¡°ë¬¸', []))}ê°œ ì¡°ë¬¸)")
            else:
                st.error(f"âŒ '{law_name}' ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        
        return results
    
    # 3ë‹¨ ë¹„êµ ê´€ë ¨ ë©”ì†Œë“œë“¤
    def get_three_stage_comparison_detail(self, law_id: str, comparison_type: int = 1) -> Optional[Dict]:
        """3ë‹¨ ë¹„êµ ë³¸ë¬¸ ìƒì„¸ ì¡°íšŒ
        
        Args:
            law_id: ë²•ë ¹ ID
            comparison_type: ë¹„êµ ì¢…ë¥˜ (1: ì¸ìš©ì¡°ë¬¸, 2: ìœ„ì„ì¡°ë¬¸)
            
        Returns:
            3ë‹¨ ë¹„êµ ìƒì„¸ ë°ì´í„° ë˜ëŠ” None
        """
        url = f"{self.base_url}lawService.do"
        params = {
            "OC": self.oc,
            "target": "thdCmp",
            "type": "XML",
            "ID": law_id,
            "knd": comparison_type
        }
        
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            # XML íŒŒì‹±
            root = ET.fromstring(response.content)
            return self._parse_comparison_detail_xml(root, comparison_type)
            
        except Exception as e:
            st.error(f"3ë‹¨ ë¹„êµ ìƒì„¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            if hasattr(response, 'text'):
                print("ì„œë²„ ì‘ë‹µ:", response.text[:500])
            return None
    
    def _parse_comparison_detail_xml(self, root, comparison_type: int) -> Dict:
        """3ë‹¨ ë¹„êµ ìƒì„¸ XML íŒŒì‹±"""
        if comparison_type == 1:  # ì¸ìš©ì¡°ë¬¸
            return self._parse_citation_comparison(root)
        else:  # ìœ„ì„ì¡°ë¬¸
            return self._parse_delegation_comparison(root)
    
    def _parse_citation_comparison(self, root) -> Dict:
        """ì¸ìš©ì¡°ë¬¸ 3ë‹¨ ë¹„êµ íŒŒì‹±"""
        result = {
            "ê¸°ë³¸ì •ë³´": {
                "ë²•ë ¹ID": root.findtext(".//ë²•ë ¹ID"),
                "ë²•ë ¹ëª…": root.findtext(".//ë²•ë ¹ëª…"),
                "ì‹œí–‰ë ¹ID": root.findtext(".//ì‹œí–‰ë ¹ID"),
                "ì‹œí–‰ë ¹ëª…": root.findtext(".//ì‹œí–‰ë ¹ëª…"),
                "ì‹œí–‰ê·œì¹™ID": root.findtext(".//ì‹œí–‰ê·œì¹™ID"),
                "ì‹œí–‰ê·œì¹™ëª…": root.findtext(".//ì‹œí–‰ê·œì¹™ëª…"),
                "ì‹œí–‰ì¼ì": root.findtext(".//ì‹œí–‰ì¼ì")
            },
            "ì¸ìš©ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ": []
        }
        
        # ë²•ë¥ ì¡°ë¬¸ë“¤ íŒŒì‹±
        for law_article in root.findall(".//ë²•ë¥ ì¡°ë¬¸"):
            article_data = {
                "ì¡°ë²ˆí˜¸": law_article.findtext("ì¡°ë²ˆí˜¸"),
                "ì¡°ì œëª©": law_article.findtext("ì¡°ì œëª©"), 
                "ì¡°ë‚´ìš©": law_article.findtext("ì¡°ë‚´ìš©"),
                "ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡": [],
                "ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡": [],
                "ìœ„ì„í–‰ì •ê·œì¹™ëª©ë¡": []
            }
            
            # ì‹œí–‰ë ¹ì¡°ë¬¸ íŒŒì‹±
            for decree_article in law_article.findall(".//ì‹œí–‰ë ¹ì¡°ë¬¸"):
                decree_data = {
                    "ì¡°ë²ˆí˜¸": decree_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ì œëª©": decree_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": decree_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡"].append(decree_data)
            
            # ì‹œí–‰ê·œì¹™ì¡°ë¬¸ íŒŒì‹±
            for rule_article in law_article.findall(".//ì‹œí–‰ê·œì¹™ì¡°ë¬¸"):
                rule_data = {
                    "ì¡°ë²ˆí˜¸": rule_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ì œëª©": rule_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": rule_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡"].append(rule_data)
            
            # ìœ„ì„í–‰ì •ê·œì¹™ íŒŒì‹±
            for admin_rule in law_article.findall(".//ìœ„ì„í–‰ì •ê·œì¹™"):
                admin_data = {
                    "ìœ„ì„í–‰ì •ê·œì¹™ëª…": admin_rule.findtext("ìœ„ì„í–‰ì •ê·œì¹™ëª…"),
                    "ìœ„ì„í–‰ì •ê·œì¹™ì¡°ë²ˆí˜¸": admin_rule.findtext("ìœ„ì„í–‰ì •ê·œì¹™ì¡°ë²ˆí˜¸"),
                    "ì¡°ë‚´ìš©": admin_rule.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ìœ„ì„í–‰ì •ê·œì¹™ëª©ë¡"].append(admin_data)
            
            result["ì¸ìš©ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ"].append(article_data)
        
        return result
    
    def _parse_delegation_comparison(self, root) -> Dict:
        """ìœ„ì„ì¡°ë¬¸ 3ë‹¨ ë¹„êµ íŒŒì‹±"""
        result = {
            "ê¸°ë³¸ì •ë³´": {
                "ë²•ë ¹ID": root.findtext(".//ë²•ë ¹ID"),
                "ë²•ë ¹ëª…": root.findtext(".//ë²•ë ¹ëª…"),
                "ë²•ë ¹ì¼ë ¨ë²ˆí˜¸": root.findtext(".//ë²•ë ¹ì¼ë ¨ë²ˆí˜¸"),
                "ê³µí¬ì¼ì": root.findtext(".//ê³µí¬ì¼ì"),
                "ê³µí¬ë²ˆí˜¸": root.findtext(".//ê³µí¬ë²ˆí˜¸"),
                "ë²•ì¢…êµ¬ë¶„": root.findtext(".//ë²•ì¢…êµ¬ë¶„"),
                "ì‹œí–‰ì¼ì": root.findtext(".//ì‹œí–‰ì¼ì"),
                "ì œê°œì •êµ¬ë¶„": root.findtext(".//ì œê°œì •êµ¬ë¶„"),
                "ì‚¼ë‹¨ë¹„êµì¡´ì¬ì—¬ë¶€": root.findtext(".//ì‚¼ë‹¨ë¹„êµì¡´ì¬ì—¬ë¶€")
            },
            "ìœ„ì„ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ": []
        }
        
        # ë²•ë¥ ì¡°ë¬¸ë“¤ íŒŒì‹±
        for law_article in root.findall(".//ë²•ë¥ ì¡°ë¬¸"):
            article_data = {
                "ì¡°ë²ˆí˜¸": law_article.findtext("ì¡°ë²ˆí˜¸"),
                "ì¡°ê°€ì§€ë²ˆí˜¸": law_article.findtext("ì¡°ê°€ì§€ë²ˆí˜¸"),
                "ì¡°ì œëª©": law_article.findtext("ì¡°ì œëª©"), 
                "ì¡°ë‚´ìš©": law_article.findtext("ì¡°ë‚´ìš©"),
                "ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡": [],
                "ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡": []
            }
            
            # ì‹œí–‰ë ¹ì¡°ë¬¸ íŒŒì‹±
            for decree_article in law_article.findall(".//ì‹œí–‰ë ¹ì¡°ë¬¸"):
                decree_data = {
                    "ì¡°ë²ˆí˜¸": decree_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ê°€ì§€ë²ˆí˜¸": decree_article.findtext("ì¡°ê°€ì§€ë²ˆí˜¸"),
                    "ì¡°ì œëª©": decree_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": decree_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡"].append(decree_data)
            
            # ì‹œí–‰ê·œì¹™ì¡°ë¬¸ íŒŒì‹±
            for rule_article in law_article.findall(".//ì‹œí–‰ê·œì¹™ì¡°ë¬¸"):
                rule_data = {
                    "ì¡°ë²ˆí˜¸": rule_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ê°€ì§€ë²ˆí˜¸": rule_article.findtext("ì¡°ê°€ì§€ë²ˆí˜¸"),
                    "ì¡°ì œëª©": rule_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": rule_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡"].append(rule_data)
            
            result["ìœ„ì„ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ"].append(article_data)
        
        return result
    
    def _extract_title_in_parentheses(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        if not text:
            return ""
        
        # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ (ì²« ë²ˆì§¸ ê´„í˜¸ë§Œ)
        match = re.search(r'\(([^)]+)\)', text)
        if match:
            return match.group(1)
        return ""
    
    def convert_three_stage_comparison_to_chatbot_format(self, comparison_data: Dict) -> List[Dict]:
        """3ë‹¨ ë¹„êµ ë°ì´í„°ë¥¼ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            comparison_data: íŒŒì‹±ëœ 3ë‹¨ ë¹„êµ ë°ì´í„°
            
        Returns:
            {"ì¡°ë²ˆí˜¸", "ì œëª©", "ë‚´ìš©"} í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        """
        result = []
        
        # ì¸ìš©ì¡°ë¬¸ ë˜ëŠ” ìœ„ì„ì¡°ë¬¸ ë°ì´í„° ì²˜ë¦¬
        articles = comparison_data.get("ì¸ìš©ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ", [])
        if not articles:
            articles = comparison_data.get("ìœ„ì„ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ", [])
            
        for article in articles:
            # í•˜ìœ„ë²•ë ¹ë‚´ìš© í†µí•©
            sub_law_content = ""
            
            # ì‹œí–‰ë ¹ì¡°ë¬¸ ë‚´ìš© ì¶”ê°€
            for decree in article.get("ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡", []):
                if decree.get("ì¡°ë‚´ìš©"):
                    decree_title = self._extract_title_in_parentheses(decree.get('ì¡°ì œëª©', ''))
                    sub_law_content += f"[ì‹œí–‰ë ¹ {decree.get('ì¡°ë²ˆí˜¸', '')}] {decree_title}\n"
                    sub_law_content += f"{decree.get('ì¡°ë‚´ìš©', '')}\n\n"
            
            # ì‹œí–‰ê·œì¹™ì¡°ë¬¸ ë‚´ìš© ì¶”ê°€
            for rule in article.get("ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡", []):
                if rule.get("ì¡°ë‚´ìš©"):
                    rule_title = self._extract_title_in_parentheses(rule.get('ì¡°ì œëª©', ''))
                    sub_law_content += f"[ì‹œí–‰ê·œì¹™ {rule.get('ì¡°ë²ˆí˜¸', '')}] {rule_title}\n"
                    sub_law_content += f"{rule.get('ì¡°ë‚´ìš©', '')}\n\n"
            
            # ìœ„ì„í–‰ì •ê·œì¹™ ë‚´ìš© ì¶”ê°€
            for admin in article.get("ìœ„ì„í–‰ì •ê·œì¹™ëª©ë¡", []):
                if admin.get("ì¡°ë‚´ìš©"):
                    sub_law_content += f"[ìœ„ì„í–‰ì •ê·œì¹™] {admin.get('ìœ„ì„í–‰ì •ê·œì¹™ëª…', '')}\n"
                    sub_law_content += f"{admin.get('ì¡°ë‚´ìš©', '')}\n\n"
            
            # ë²•ì¡°ë¬¸ ì œëª©ì—ì„œ ê´„í˜¸ ì•ˆ ë‚´ìš©ë§Œ ì¶”ì¶œ
            title = self._extract_title_in_parentheses(article.get("ì¡°ì œëª©", ""))
            
            # ë²•ì¡°ë¬¸ë‚´ìš©ê³¼ í•˜ìœ„ë²•ë ¹ë‚´ìš©ì„ í•©ì³ì„œ "ë‚´ìš©" ìƒì„±
            law_content = article.get("ì¡°ë‚´ìš©", "")
            combined_content = law_content
            if sub_law_content.strip():
                combined_content += "\n" + sub_law_content.strip()
            
            formatted_article = {
                "ì¡°ë²ˆí˜¸": article.get("ì¡°ë²ˆí˜¸", ""),
                "ì œëª©": title,
                "ë‚´ìš©": combined_content
            }
            
            result.append(formatted_article)
        
        return result
    
    def filter_empty_titles(self, chatbot_data: List[Dict]) -> List[Dict]:
        """ì œëª©ì´ ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ nullì¸ í•­ëª©ë“¤ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            chatbot_data: ì±—ë´‡ í˜•ì‹ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì œëª©ì´ ë¹ˆ ë¬¸ìì—´ì´ë‚˜ nullì´ ì•„ë‹Œ í•­ëª©ë“¤ë§Œ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸
        """
        filtered_data = []
        removed_count = 0
        
        for item in chatbot_data:
            title = item.get("ì œëª©")
            # None, ë¹ˆ ë¬¸ìì—´, ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì œì™¸
            if title is not None and str(title).strip():
                filtered_data.append(item)
            else:
                removed_count += 1
        
        if removed_count > 0:
            st.info(f"ğŸ“ ì œëª©ì´ ì—†ëŠ” {removed_count}ê°œ í•­ëª©ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
        
        return filtered_data
    
    def download_three_stage_comparison_as_json(self, law_name: str) -> Optional[List[Dict]]:
        """ë²•ë ¹ëª…ìœ¼ë¡œ 3ë‹¨ ë¹„êµ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        
        Args:
            law_name: ë²•ë ¹ëª…
            
        Returns:
            ì±—ë´‡ìš© 3ë‹¨ ë¹„êµ ë°ì´í„° ë˜ëŠ” None
        """
        # 1. ë²•ë ¹ ID ê²€ìƒ‰
        law_id, full_law_name = self.search_law_id(law_name)
        if not law_id:
            return None
        
        # 2. 3ë‹¨ ë¹„êµ ìƒì„¸ ì¡°íšŒ (ìœ„ì„ì¡°ë¬¸)
        comparison_data = self.get_three_stage_comparison_detail(law_id, comparison_type=2)
        if not comparison_data:
            return None
        
        # 3. ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        chatbot_data = self.convert_three_stage_comparison_to_chatbot_format(comparison_data)
        
        # 4. ì œëª©ì´ ë¹ˆ ë¬¸ìì—´ì¸ í•­ëª©ë“¤ ì œê±°
        if chatbot_data:
            chatbot_data = self.filter_empty_titles(chatbot_data)
        
        return chatbot_data if chatbot_data else None

def convert_law_data_to_chatbot_format(law_data: Dict) -> List[Dict]:
    """ë²•ë ¹ ë°ì´í„°ë¥¼ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        law_data: ë²•ë ¹ APIì—ì„œ ë°›ì€ ë°ì´í„°
        
    Returns:
        ì±—ë´‡ìš© JSON í˜•ì‹ ë¦¬ìŠ¤íŠ¸ (ë¹ˆ ì œëª© í•­ëª© ì œê±°ë¨)
    """
    chatbot_data = []
    
    for article in law_data.get("ì¡°ë¬¸", []):
        chatbot_item = {
            "ì¡°ë²ˆí˜¸": article.get("ì¡°ë¬¸ë²ˆí˜¸", ""),
            "ì œëª©": article.get("ì¡°ë¬¸ì œëª©", ""),
            "ë‚´ìš©": article.get("ì¡°ë¬¸ë‚´ìš©", "")
        }
        chatbot_data.append(chatbot_item)
    
    # ì œëª©ì´ ë¹ˆ ë¬¸ìì—´ì´ë‚˜ nullì¸ í•­ëª©ë“¤ ì œê±°
    filtered_data = []
    removed_count = 0
    
    for item in chatbot_data:
        title = item.get("ì œëª©")
        # None, ë¹ˆ ë¬¸ìì—´, ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì œì™¸
        if title is not None and str(title).strip():
            filtered_data.append(item)
        else:
            removed_count += 1
    
    if removed_count > 0:
        st.info(f"ğŸ“ ë²•ë ¹ ë°ì´í„°ì—ì„œ ì œëª©ì´ ì—†ëŠ” {removed_count}ê°œ í•­ëª©ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
    
    return filtered_data