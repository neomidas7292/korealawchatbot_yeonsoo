import requests
import xml.etree.ElementTree as ET
import json
import os
import logging
import re
from typing import Optional, Tuple, List, Dict
import streamlit as st

class LawAPI:
    def __init__(self, oc: str):
        """ë²•ë ¹ API í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            oc: API í‚¤
        """
        self.oc = oc
        self.base_url = "http://www.law.go.kr/DRF/"
    
    def search_law_id(self, query: str) -> Tuple[Optional[str], Optional[str]]:
        """ë²•ë ¹ëª…ìœ¼ë¡œ ê²€ìƒ‰í•´ì„œ ì²« ë²ˆì§¸ ë²•ë ¹ì˜ IDë¥¼ ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰í•  ë²•ë ¹ëª…
            
        Returns:
            Tuple[ë²•ë ¹ID, ë²•ë ¹ëª…í•œê¸€] ë˜ëŠ” (None, None)
        """
        url = f"{self.base_url}lawSearch.do"
        params = {
            "OC": self.oc,
            "target": "law",
            "type": "XML",
            "query": query
        }

        response = None
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()

            root = ET.fromstring(response.content)
            law = root.find("law")

            if law is None:
                return None, None

            return law.findtext("ë²•ë ¹ID"), law.findtext("ë²•ë ¹ëª…í•œê¸€")

        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì„œë²„ì—ì„œ ë°›ì€ ì‹¤ì œ ì‘ë‹µì„ ì¶œë ¥ (ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
            if response is not None and hasattr(response, "text"):
                print("===== API ì„œë²„ ì‹¤ì œ ì‘ë‹µ ë‚´ìš© =====")
                print(response.text)
                print("===================================")
            logging.exception("ë²•ë ¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            st.error(f"ë²•ë ¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None
    
    def get_law_json(self, law_id: str) -> Optional[Dict]:
        """ë²•ë ¹ IDë¡œ ë²•ë ¹ ë°ì´í„° ì¡°íšŒ
        
        Args:
            law_id: ë²•ë ¹ ID
            
        Returns:
            ë²•ë ¹ ë°ì´í„° ë˜ëŠ” None
        """
        url = f"{self.base_url}lawService.do"
        params = {
            "OC": self.oc,
            "target": "law",
            "type": "JSON",
            "ID": law_id
        }
        
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        
        except Exception as e:
            st.error(f"ë²•ë ¹ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def clean_law_data(self, law_data: Dict) -> Dict:
        """í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì •ì œëœ ë°ì´í„° ë°˜í™˜ (ì¡° ë‹¨ìœ„ë¡œ ê³ ì •)
        
        Args:
            law_data: ë²•ë ¹ ì›ë³¸ ë°ì´í„°
            
        Returns:
            ì •ì œëœ ë²•ë ¹ ë°ì´í„°
        """
        # ê¸°ë³¸ì •ë³´ì—ì„œ ë²•ë ¹IDì™€ ë²•ë ¹ëª… ì¶”ì¶œ
        basic_info = law_data.get("ë²•ë ¹", {}).get("ê¸°ë³¸ì •ë³´", {})
        cleaned_data = {
            "ë²•ë ¹ID": basic_info.get("ë²•ë ¹ID"),
            "ë²•ë ¹ëª…_í•œê¸€": basic_info.get("ë²•ë ¹ëª…_í•œê¸€"),
            "ì¡°ë¬¸": []
        }
        
        # ì¡°ë¬¸ ë°ì´í„° ì¶”ì¶œ
        law_content = law_data.get("ë²•ë ¹", {})
        if "ì¡°ë¬¸" in law_content:
            articles = law_content["ì¡°ë¬¸"]
            if "ì¡°ë¬¸ë‹¨ìœ„" in articles:
                # ì¡°ë¬¸ë‹¨ìœ„ê°€ ë‹¨ì¼ í•­ëª©ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ê¸°
                if isinstance(articles["ì¡°ë¬¸ë‹¨ìœ„"], dict):
                    articles_list = [articles["ì¡°ë¬¸ë‹¨ìœ„"]]
                else:
                    articles_list = articles["ì¡°ë¬¸ë‹¨ìœ„"]

                for article in articles_list:
                    full_content = article.get("ì¡°ë¬¸ë‚´ìš©", "")
                    
                    # í•­ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì¡°ë¬¸ë‚´ìš©ì— ì¶”ê°€
                    if "í•­" in article:
                        full_content += self._extract_all_content_from_items(article["í•­"])
                    
                    article_data = {
                        "ì¡°ë¬¸ë²ˆí˜¸": article.get("ì¡°ë¬¸ë²ˆí˜¸"),
                        "ì¡°ë¬¸ì œëª©": article.get("ì¡°ë¬¸ì œëª©"),
                        "ì¡°ë¬¸ë‚´ìš©": full_content.strip()  # ê³µë°± ì œê±°
                    }
                    cleaned_data["ì¡°ë¬¸"].append(article_data)
        
        return cleaned_data
    
    def _extract_all_content_from_items(self, items) -> str:
        """í•­ ë°ì´í„°ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œ"""
        content = ""
        
        # itemsê°€ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ì¸ ê²½ìš°ì—ë„ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
        if isinstance(items, dict):
            items = [items]  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜ë³µë¬¸ ì²˜ë¦¬

        if isinstance(items, list):
            for item in items:
                hang_content = item.get("í•­ë‚´ìš©")
                if hang_content:
                    # í•­ë‚´ìš©ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(hang_content, list):
                        content += "\n" + " ".join(str(i) for i in hang_content)
                    else:
                        content += "\n" + str(hang_content)
                
                if "í˜¸" in item:
                    content += self._extract_all_content_from_subitems(item["í˜¸"])
        
        return content
    
    def _extract_all_content_from_subitems(self, subitems) -> str:
        """í˜¸ ë°ì´í„°ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œ"""
        content = ""
        
        # subitemsê°€ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ì¸ ê²½ìš°ì—ë„ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
        if isinstance(subitems, dict):
            subitems = [subitems]  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜ë³µë¬¸ ì²˜ë¦¬

        if isinstance(subitems, list):
            for subitem in subitems:
                ho_content = subitem.get("í˜¸ë‚´ìš©")
                if ho_content:
                    # í˜¸ë‚´ìš©ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(ho_content, list):
                        content += "\n" + " ".join(str(i) for i in ho_content)
                    else:
                        content += "\n" + str(ho_content)
        
        return content
    
    def download_law_as_json(self, query: str) -> Optional[Dict]:
        """ë²•ë ¹ì„ ê²€ìƒ‰í•˜ì—¬ JSON ë°ì´í„°ë¡œ ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰í•  ë²•ë ¹ëª…
            
        Returns:
            ì •ì œëœ ë²•ë ¹ ë°ì´í„° ë˜ëŠ” None
        """
        # 1. ë²•ë ¹ ID ê²€ìƒ‰
        law_id, law_name = self.search_law_id(query)
        if not law_id:
            return None
        
        # 2. ë²•ë ¹ ë°ì´í„° ì¡°íšŒ
        law_data = self.get_law_json(law_id)
        if not law_data:
            return None
        
        # 3. ë°ì´í„° ì •ì œ
        cleaned_data = self.clean_law_data(law_data)
        
        return cleaned_data
    
    def save_law_json_file(self, query: str, filename: str) -> bool:
        """ë²•ë ¹ì„ ê²€ìƒ‰í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            query: ê²€ìƒ‰í•  ë²•ë ¹ëª…
            filename: ì €ì¥í•  íŒŒì¼ëª…
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        cleaned_data = self.download_law_as_json(query)
        if not cleaned_data:
            return False
        
        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(cleaned_data, f, ensure_ascii=False, indent=4)
            return True
        except Exception as e:
            st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def batch_download_laws(self, law_names: List[str]) -> Dict[str, Dict]:
        """ì—¬ëŸ¬ ë²•ë ¹ì„ ì¼ê´„ ë‹¤ìš´ë¡œë“œ
        
        Args:
            law_names: ë‹¤ìš´ë¡œë“œí•  ë²•ë ¹ëª… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            {ë²•ë ¹ëª…: ë²•ë ¹ë°ì´í„°} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        for law_name in law_names:
            st.info(f"'{law_name}' ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            cleaned_data = self.download_law_as_json(law_name)
            if cleaned_data:
                results[law_name] = cleaned_data
                st.success(f"âœ… '{law_name}' ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({len(cleaned_data.get('ì¡°ë¬¸', []))}ê°œ ì¡°ë¬¸)")
            else:
                st.error(f"âŒ '{law_name}' ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        
        return results
    
    # 3ë‹¨ ë¹„êµ ê´€ë ¨ ë©”ì†Œë“œë“¤
    def get_three_stage_comparison_detail(self, law_id: str, comparison_type: int = 1) -> Optional[Dict]:
        """3ë‹¨ ë¹„êµ ë³¸ë¬¸ ìƒì„¸ ì¡°íšŒ
        
        Args:
            law_id: ë²•ë ¹ ID
            comparison_type: ë¹„êµ ì¢…ë¥˜ (1: ì¸ìš©ì¡°ë¬¸, 2: ìœ„ì„ì¡°ë¬¸)
            
        Returns:
            3ë‹¨ ë¹„êµ ìƒì„¸ ë°ì´í„° ë˜ëŠ” None
        """
        url = f"{self.base_url}lawService.do"
        params = {
            "OC": self.oc,
            "target": "thdCmp",
            "type": "XML",
            "ID": law_id,
            "knd": comparison_type
        }
        
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            # XML íŒŒì‹±
            root = ET.fromstring(response.content)
            return self._parse_comparison_detail_xml(root, comparison_type)
            
        except Exception as e:
            st.error(f"3ë‹¨ ë¹„êµ ìƒì„¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            if hasattr(response, 'text'):
                print("ì„œë²„ ì‘ë‹µ:", response.text[:500])
            return None
    
    def _parse_comparison_detail_xml(self, root, comparison_type: int) -> Dict:
        """3ë‹¨ ë¹„êµ ìƒì„¸ XML íŒŒì‹±"""
        if comparison_type == 1:  # ì¸ìš©ì¡°ë¬¸
            return self._parse_citation_comparison(root)
        else:  # ìœ„ì„ì¡°ë¬¸
            return self._parse_delegation_comparison(root)
    
    def _parse_citation_comparison(self, root) -> Dict:
        """ì¸ìš©ì¡°ë¬¸ 3ë‹¨ ë¹„êµ íŒŒì‹±"""
        result = {
            "ê¸°ë³¸ì •ë³´": {
                "ë²•ë ¹ID": root.findtext(".//ë²•ë ¹ID"),
                "ë²•ë ¹ëª…": root.findtext(".//ë²•ë ¹ëª…"),
                "ì‹œí–‰ë ¹ID": root.findtext(".//ì‹œí–‰ë ¹ID"),
                "ì‹œí–‰ë ¹ëª…": root.findtext(".//ì‹œí–‰ë ¹ëª…"),
                "ì‹œí–‰ê·œì¹™ID": root.findtext(".//ì‹œí–‰ê·œì¹™ID"),
                "ì‹œí–‰ê·œì¹™ëª…": root.findtext(".//ì‹œí–‰ê·œì¹™ëª…"),
                "ì‹œí–‰ì¼ì": root.findtext(".//ì‹œí–‰ì¼ì")
            },
            "ì¸ìš©ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ": []
        }
        
        # ë²•ë¥ ì¡°ë¬¸ë“¤ íŒŒì‹±
        for law_article in root.findall(".//ë²•ë¥ ì¡°ë¬¸"):
            article_data = {
                "ì¡°ë²ˆí˜¸": law_article.findtext("ì¡°ë²ˆí˜¸"),
                "ì¡°ì œëª©": law_article.findtext("ì¡°ì œëª©"), 
                "ì¡°ë‚´ìš©": law_article.findtext("ì¡°ë‚´ìš©"),
                "ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡": [],
                "ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡": [],
                "ìœ„ì„í–‰ì •ê·œì¹™ëª©ë¡": []
            }
            
            # ì‹œí–‰ë ¹ì¡°ë¬¸ íŒŒì‹±
            for decree_article in law_article.findall(".//ì‹œí–‰ë ¹ì¡°ë¬¸"):
                decree_data = {
                    "ì¡°ë²ˆí˜¸": decree_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ì œëª©": decree_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": decree_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡"].append(decree_data)
            
            # ì‹œí–‰ê·œì¹™ì¡°ë¬¸ íŒŒì‹±
            for rule_article in law_article.findall(".//ì‹œí–‰ê·œì¹™ì¡°ë¬¸"):
                rule_data = {
                    "ì¡°ë²ˆí˜¸": rule_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ì œëª©": rule_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": rule_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡"].append(rule_data)
            
            # ìœ„ì„í–‰ì •ê·œì¹™ íŒŒì‹±
            for admin_rule in law_article.findall(".//ìœ„ì„í–‰ì •ê·œì¹™"):
                admin_data = {
                    "ìœ„ì„í–‰ì •ê·œì¹™ëª…": admin_rule.findtext("ìœ„ì„í–‰ì •ê·œì¹™ëª…"),
                    "ìœ„ì„í–‰ì •ê·œì¹™ì¡°ë²ˆí˜¸": admin_rule.findtext("ìœ„ì„í–‰ì •ê·œì¹™ì¡°ë²ˆí˜¸"),
                    "ì¡°ë‚´ìš©": admin_rule.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ìœ„ì„í–‰ì •ê·œì¹™ëª©ë¡"].append(admin_data)
            
            result["ì¸ìš©ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ"].append(article_data)
        
        return result
    
    def _parse_delegation_comparison(self, root) -> Dict:
        """ìœ„ì„ì¡°ë¬¸ 3ë‹¨ ë¹„êµ íŒŒì‹±"""
        result = {
            "ê¸°ë³¸ì •ë³´": {
                "ë²•ë ¹ID": root.findtext(".//ë²•ë ¹ID"),
                "ë²•ë ¹ëª…": root.findtext(".//ë²•ë ¹ëª…"),
                "ë²•ë ¹ì¼ë ¨ë²ˆí˜¸": root.findtext(".//ë²•ë ¹ì¼ë ¨ë²ˆí˜¸"),
                "ê³µí¬ì¼ì": root.findtext(".//ê³µí¬ì¼ì"),
                "ê³µí¬ë²ˆí˜¸": root.findtext(".//ê³µí¬ë²ˆí˜¸"),
                "ë²•ì¢…êµ¬ë¶„": root.findtext(".//ë²•ì¢…êµ¬ë¶„"),
                "ì‹œí–‰ì¼ì": root.findtext(".//ì‹œí–‰ì¼ì"),
                "ì œê°œì •êµ¬ë¶„": root.findtext(".//ì œê°œì •êµ¬ë¶„"),
                "ì‚¼ë‹¨ë¹„êµì¡´ì¬ì—¬ë¶€": root.findtext(".//ì‚¼ë‹¨ë¹„êµì¡´ì¬ì—¬ë¶€")
            },
            "ìœ„ì„ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ": []
        }
        
        # ë²•ë¥ ì¡°ë¬¸ë“¤ íŒŒì‹±
        for law_article in root.findall(".//ë²•ë¥ ì¡°ë¬¸"):
            article_data = {
                "ì¡°ë²ˆí˜¸": law_article.findtext("ì¡°ë²ˆí˜¸"),
                "ì¡°ê°€ì§€ë²ˆí˜¸": law_article.findtext("ì¡°ê°€ì§€ë²ˆí˜¸"),
                "ì¡°ì œëª©": law_article.findtext("ì¡°ì œëª©"), 
                "ì¡°ë‚´ìš©": law_article.findtext("ì¡°ë‚´ìš©"),
                "ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡": [],
                "ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡": []
            }
            
            # ì‹œí–‰ë ¹ì¡°ë¬¸ íŒŒì‹±
            for decree_article in law_article.findall(".//ì‹œí–‰ë ¹ì¡°ë¬¸"):
                decree_data = {
                    "ì¡°ë²ˆí˜¸": decree_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ê°€ì§€ë²ˆí˜¸": decree_article.findtext("ì¡°ê°€ì§€ë²ˆí˜¸"),
                    "ì¡°ì œëª©": decree_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": decree_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡"].append(decree_data)
            
            # ì‹œí–‰ê·œì¹™ì¡°ë¬¸ íŒŒì‹±
            for rule_article in law_article.findall(".//ì‹œí–‰ê·œì¹™ì¡°ë¬¸"):
                rule_data = {
                    "ì¡°ë²ˆí˜¸": rule_article.findtext("ì¡°ë²ˆí˜¸"),
                    "ì¡°ê°€ì§€ë²ˆí˜¸": rule_article.findtext("ì¡°ê°€ì§€ë²ˆí˜¸"),
                    "ì¡°ì œëª©": rule_article.findtext("ì¡°ì œëª©"),
                    "ì¡°ë‚´ìš©": rule_article.findtext("ì¡°ë‚´ìš©")
                }
                article_data["ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡"].append(rule_data)
            
            result["ìœ„ì„ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ"].append(article_data)
        
        return result
    
    def _extract_title_in_parentheses(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        if not text:
            return ""
        
        # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ (ì²« ë²ˆì§¸ ê´„í˜¸ë§Œ)
        match = re.search(r'\(([^)]+)\)', text)
        if match:
            return match.group(1)
        return ""
    
    def convert_three_stage_comparison_to_chatbot_format(self, comparison_data: Dict) -> List[Dict]:
        """3ë‹¨ ë¹„êµ ë°ì´í„°ë¥¼ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            comparison_data: íŒŒì‹±ëœ 3ë‹¨ ë¹„êµ ë°ì´í„°
            
        Returns:
            {"ì¡°ë²ˆí˜¸", "ì œëª©", "ë‚´ìš©"} í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        """
        result = []
        
        # ì¸ìš©ì¡°ë¬¸ ë˜ëŠ” ìœ„ì„ì¡°ë¬¸ ë°ì´í„° ì²˜ë¦¬
        articles = comparison_data.get("ì¸ìš©ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ", [])
        if not articles:
            articles = comparison_data.get("ìœ„ì„ì¡°ë¬¸ì‚¼ë‹¨ë¹„êµ", [])
            
        for article in articles:
            # í•˜ìœ„ë²•ë ¹ë‚´ìš© í†µí•©
            sub_law_content = ""
            
            # ì‹œí–‰ë ¹ì¡°ë¬¸ ë‚´ìš© ì¶”ê°€
            for decree in article.get("ì‹œí–‰ë ¹ì¡°ë¬¸ëª©ë¡", []):
                if decree.get("ì¡°ë‚´ìš©"):
                    decree_title = self._extract_title_in_parentheses(decree.get('ì¡°ì œëª©', ''))
                    sub_law_content += f"[ì‹œí–‰ë ¹ {decree.get('ì¡°ë²ˆí˜¸', '')}] {decree_title}\n"
                    sub_law_content += f"{decree.get('ì¡°ë‚´ìš©', '')}\n\n"
            
            # ì‹œí–‰ê·œì¹™ì¡°ë¬¸ ë‚´ìš© ì¶”ê°€
            for rule in article.get("ì‹œí–‰ê·œì¹™ì¡°ë¬¸ëª©ë¡", []):
                if rule.get("ì¡°ë‚´ìš©"):
                    rule_title = self._extract_title_in_parentheses(rule.get('ì¡°ì œëª©', ''))
                    sub_law_content += f"[ì‹œí–‰ê·œì¹™ {rule.get('ì¡°ë²ˆí˜¸', '')}] {rule_title}\n"
                    sub_law_content += f"{rule.get('ì¡°ë‚´ìš©', '')}\n\n"
            
            # ìœ„ì„í–‰ì •ê·œì¹™ ë‚´ìš© ì¶”ê°€
            for admin in article.get("ìœ„ì„í–‰ì •ê·œì¹™ëª©ë¡", []):
                if admin.get("ì¡°ë‚´ìš©"):
                    sub_law_content += f"[ìœ„ì„í–‰ì •ê·œì¹™] {admin.get('ìœ„ì„í–‰ì •ê·œì¹™ëª…', '')}\n"
                    sub_law_content += f"{admin.get('ì¡°ë‚´ìš©', '')}\n\n"
            
            # ë²•ì¡°ë¬¸ ì œëª©ì—ì„œ ê´„í˜¸ ì•ˆ ë‚´ìš©ë§Œ ì¶”ì¶œ
            title = self._extract_title_in_parentheses(article.get("ì¡°ì œëª©", ""))
            
            # ë²•ì¡°ë¬¸ë‚´ìš©ê³¼ í•˜ìœ„ë²•ë ¹ë‚´ìš©ì„ í•©ì³ì„œ "ë‚´ìš©" ìƒì„±
            law_content = article.get("ì¡°ë‚´ìš©", "")
            combined_content = law_content
            if sub_law_content.strip():
                combined_content += "\n" + sub_law_content.strip()
            
            formatted_article = {
                "ì¡°ë²ˆí˜¸": article.get("ì¡°ë²ˆí˜¸", ""),
                "ì œëª©": title,
                "ë‚´ìš©": combined_content
            }
            
            result.append(formatted_article)
        
        return result
    
    def filter_empty_titles(self, chatbot_data: List[Dict]) -> List[Dict]:
        """ì œëª©ì´ ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ nullì¸ í•­ëª©ë“¤ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            chatbot_data: ì±—ë´‡ í˜•ì‹ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì œëª©ì´ ë¹ˆ ë¬¸ìì—´ì´ë‚˜ nullì´ ì•„ë‹Œ í•­ëª©ë“¤ë§Œ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸
        """
        filtered_data = []
        removed_count = 0
        
        for item in chatbot_data:
            title = item.get("ì œëª©")
            # None, ë¹ˆ ë¬¸ìì—´, ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì œì™¸
            if title is not None and str(title).strip():
                filtered_data.append(item)
            else:
                removed_count += 1
        
        if removed_count > 0:
            st.info(f"ğŸ“ ì œëª©ì´ ì—†ëŠ” {removed_count}ê°œ í•­ëª©ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
        
        return filtered_data
    
    def _extract_structure_title(self, content: str) -> str:
        """ì¥/ì ˆ/ê´€ì˜ ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        
        Args:
            content: "ì œ1ì¥ ì´ì¹™ <ê°œì • 2010.12.30>" ë˜ëŠ” "ì œ2ì ˆ ë²• ì ìš©ì˜ ì›ì¹™ ë“± <ê°œì • 2010.12.30>" í˜•íƒœì˜ í…ìŠ¤íŠ¸
            
        Returns:
            "ì´ì¹™" ë˜ëŠ” "ë²• ì ìš©ì˜ ì›ì¹™ ë“±" ê°™ì€ ì „ì²´ ì œëª©
        """
        if not content:
            return ""
        
        # ë¨¼ì € ê°œì • ì •ë³´ ì œê±°
        content_cleaned = re.sub(r'<[^>]*>', '', content).strip()
        
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¥/ì ˆ/ê´€ íŒ¨í„´ ì°¾ê¸° (ì˜ˆì™¸ì  ë„˜ë²„ë§ í¬í•¨)
        patterns = [
            r'ì œ\d+ì¥(?:ì˜\d+)?\s+(.+)',  # "ì œ1ì¥ ì´ì¹™" ë˜ëŠ” "ì œ3ì¥ì˜2 íŠ¹ë¡€" -> "ì´ì¹™" ë˜ëŠ” "íŠ¹ë¡€"
            r'ì œ\d+ì ˆ(?:ì˜\d+)?\s+(.+)',  # "ì œ2ì ˆ ë²• ì ìš©" ë˜ëŠ” "ì œ1ì ˆì˜2 íŠ¹ì¹™" -> "ë²• ì ìš©" ë˜ëŠ” "íŠ¹ì¹™"  
            r'ì œ\d+ê´€(?:ì˜\d+)?\s+(.+)',  # "ì œ1ê´€ ì¼ë°˜ì‚¬í•­" ë˜ëŠ” "ì œ2ê´€ì˜3 íŠ¹ë³„ê·œì •" -> "ì¼ë°˜ì‚¬í•­" ë˜ëŠ” "íŠ¹ë³„ê·œì •"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content_cleaned)
            if match:
                title = match.group(1).strip()
                return title
        
        # íŒ¨í„´ì´ ë§¤ì¹˜ë˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
        return content_cleaned
    
    def _identify_structure_type(self, content: str) -> str:
        """ë‚´ìš©ì„ ë³´ê³  ì¥/ì ˆ/ê´€/ì¡° ì¤‘ ì–´ëŠ ê²ƒì¸ì§€ íŒë³„
        
        Args:
            content: í•­ëª©ì˜ ë‚´ìš©
            
        Returns:
            "ì¥", "ì ˆ", "ê´€", "ì¡°" ì¤‘ í•˜ë‚˜
        """
        if not content:
            return "ì¡°"
        
        # ë‚´ìš©ì´ "ì œXì¥", "ì œXì ˆ", "ì œXê´€" íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸ (ì˜ˆì™¸ì  ë„˜ë²„ë§ í¬í•¨)
        if re.match(r'^ì œ\d+ì¥(?:ì˜\d+)?', content.strip()):
            return "ì¥"
        elif re.match(r'^ì œ\d+ì ˆ(?:ì˜\d+)?', content.strip()):
            return "ì ˆ"
        elif re.match(r'^ì œ\d+ê´€(?:ì˜\d+)?', content.strip()):
            return "ê´€"
        else:
            return "ì¡°"
    
    def _build_structure_hierarchy(self, chatbot_data: List[Dict]) -> List[Dict]:
        """ì±—ë´‡ ë°ì´í„°ì—ì„œ ì¥/ì ˆ/ê´€ êµ¬ì¡° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê° ì¡°ë¬¸ì— ë§¤í•‘
        
        Args:
            chatbot_data: ì›ë³¸ ì±—ë´‡ í˜•ì‹ ë°ì´í„°
            
        Returns:
            ìƒìœ„ êµ¬ì¡° ì •ë³´ê°€ ì¶”ê°€ëœ ì±—ë´‡ ë°ì´í„°
        """
        current_jang = ""  # í˜„ì¬ ì¥
        current_jeol = ""  # í˜„ì¬ ì ˆ
        current_gwan = ""  # í˜„ì¬ ê´€
        
        result = []
        
        for item in chatbot_data:
            content = item.get("ë‚´ìš©", "")
            title = item.get("ì œëª©", "")
            structure_type = self._identify_structure_type(content)
            
            if structure_type == "ì¥":
                current_jang = self._extract_structure_title(content)
                current_jeol = ""  # ìƒˆë¡œìš´ ì¥ì´ë©´ ì ˆê³¼ ê´€ ì´ˆê¸°í™”
                current_gwan = ""
                continue  # ì¥ í•­ëª©ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
                
            elif structure_type == "ì ˆ":
                current_jeol = self._extract_structure_title(content)
                current_gwan = ""  # ìƒˆë¡œìš´ ì ˆì´ë©´ ê´€ ì´ˆê¸°í™”
                continue  # ì ˆ í•­ëª©ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
                
            elif structure_type == "ê´€":
                current_gwan = self._extract_structure_title(content)
                continue  # ê´€ í•­ëª©ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
                
            else:  # ì¡°ë¬¸ì¸ ê²½ìš°
                # ìƒìœ„ êµ¬ì¡°ë“¤ì„ ì œëª©ì— í•©ì¹˜ê¸°
                enhanced_title = self._combine_structure_titles(
                    current_jang, current_jeol, current_gwan, title
                )
                
                enhanced_item = {
                    "ì¡°ë²ˆí˜¸": item.get("ì¡°ë²ˆí˜¸", ""),
                    "ì œëª©": enhanced_title,
                    "ë‚´ìš©": content
                }
                result.append(enhanced_item)
        
        return result
    
    def _combine_structure_titles(self, jang: str, jeol: str, gwan: str, original_title: str) -> str:
        """ì¥/ì ˆ/ê´€ ì œëª©ë“¤ì„ ì›ë˜ ì œëª©ê³¼ í•©ì¹˜ê¸°
        
        Args:
            jang: ì¥ ì œëª©
            jeol: ì ˆ ì œëª©
            gwan: ê´€ ì œëª©
            original_title: ì›ë˜ ì¡°ë¬¸ ì œëª©
            
        Returns:
            í•©ì³ì§„ ì œëª© (ì‰¼í‘œë¡œ êµ¬ë¶„)
        """
        parts = []
        
        if jang:
            parts.append(jang)
        if jeol:
            parts.append(jeol)
        if gwan:
            parts.append(gwan)
        if original_title:
            parts.append(original_title)
        
        return ", ".join(parts)

    def download_three_stage_comparison_as_json(self, law_name: str) -> Optional[List[Dict]]:
        """ë²•ë ¹ëª…ìœ¼ë¡œ 3ë‹¨ ë¹„êµ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ìƒìœ„ êµ¬ì¡° ì œëª© í¬í•¨)
        
        Args:
            law_name: ë²•ë ¹ëª…
            
        Returns:
            ì±—ë´‡ìš© 3ë‹¨ ë¹„êµ ë°ì´í„° ë˜ëŠ” None
        """
        # 1. ë²•ë ¹ ID ê²€ìƒ‰
        law_id, full_law_name = self.search_law_id(law_name)
        if not law_id:
            return None
        
        # 2. 3ë‹¨ ë¹„êµ ìƒì„¸ ì¡°íšŒ (ìœ„ì„ì¡°ë¬¸)
        comparison_data = self.get_three_stage_comparison_detail(law_id, comparison_type=2)
        if not comparison_data:
            return None
        
        # 3. ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        chatbot_data = self.convert_three_stage_comparison_to_chatbot_format(comparison_data)
        
        # 4. ì¥/ì ˆ/ê´€ êµ¬ì¡° ì •ë³´ë¥¼ ì¡°ë¬¸ì— ë§¤í•‘
        if chatbot_data:
            chatbot_data = self._build_structure_hierarchy(chatbot_data)
        
        return chatbot_data if chatbot_data else None

def convert_law_data_to_chatbot_format(law_data: Dict) -> List[Dict]:
    """ë²•ë ¹ ë°ì´í„°ë¥¼ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ìƒìœ„ êµ¬ì¡° ì œëª© í¬í•¨)
    
    Args:
        law_data: ë²•ë ¹ APIì—ì„œ ë°›ì€ ë°ì´í„°
        
    Returns:
        ì±—ë´‡ìš© JSON í˜•ì‹ ë¦¬ìŠ¤íŠ¸ (ìƒìœ„ êµ¬ì¡°ê°€ ì œëª©ì— í¬í•¨ë¨)
    """
    chatbot_data = []
    
    for article in law_data.get("ì¡°ë¬¸", []):
        chatbot_item = {
            "ì¡°ë²ˆí˜¸": article.get("ì¡°ë¬¸ë²ˆí˜¸", ""),
            "ì œëª©": article.get("ì¡°ë¬¸ì œëª©", ""),
            "ë‚´ìš©": article.get("ì¡°ë¬¸ë‚´ìš©", "")
        }
        chatbot_data.append(chatbot_item)
    
    # ì¥/ì ˆ/ê´€ êµ¬ì¡° ì •ë³´ë¥¼ ì¡°ë¬¸ì— ë§¤í•‘
    enhanced_data = _build_structure_hierarchy_standalone(chatbot_data)
    
    return enhanced_data

def _extract_structure_title_standalone(content: str) -> str:
    """ì¥/ì ˆ/ê´€ì˜ ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ë…ë¦½ í•¨ìˆ˜)
    
    Args:
        content: "ì œ1ì¥ ì´ì¹™ <ê°œì • 2010.12.30>" ë˜ëŠ” "ì œ2ì ˆ ë²• ì ìš©ì˜ ì›ì¹™ ë“± <ê°œì • 2010.12.30>" í˜•íƒœì˜ í…ìŠ¤íŠ¸
        
    Returns:
        "ì´ì¹™" ë˜ëŠ” "ë²• ì ìš©ì˜ ì›ì¹™ ë“±" ê°™ì€ ì „ì²´ ì œëª©
    """
    if not content:
        return ""
    
    # ë¨¼ì € ê°œì • ì •ë³´ ì œê±°
    content_cleaned = re.sub(r'<[^>]*>', '', content).strip()
    
    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¥/ì ˆ/ê´€ íŒ¨í„´ ì°¾ê¸° (ì˜ˆì™¸ì  ë„˜ë²„ë§ í¬í•¨)
    patterns = [
        r'ì œ\d+ì¥(?:ì˜\d+)?\s+(.+)',  # "ì œ1ì¥ ì´ì¹™" ë˜ëŠ” "ì œ3ì¥ì˜2 íŠ¹ë¡€" -> "ì´ì¹™" ë˜ëŠ” "íŠ¹ë¡€"
        r'ì œ\d+ì ˆ(?:ì˜\d+)?\s+(.+)',  # "ì œ2ì ˆ ë²• ì ìš©" ë˜ëŠ” "ì œ1ì ˆì˜2 íŠ¹ì¹™" -> "ë²• ì ìš©" ë˜ëŠ” "íŠ¹ì¹™"  
        r'ì œ\d+ê´€(?:ì˜\d+)?\s+(.+)',  # "ì œ1ê´€ ì¼ë°˜ì‚¬í•­" ë˜ëŠ” "ì œ2ê´€ì˜3 íŠ¹ë³„ê·œì •" -> "ì¼ë°˜ì‚¬í•­" ë˜ëŠ” "íŠ¹ë³„ê·œì •"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content_cleaned)
        if match:
            title = match.group(1).strip()
            return title
    
    # íŒ¨í„´ì´ ë§¤ì¹˜ë˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
    return content_cleaned

def _identify_structure_type_standalone(content: str) -> str:
    """ë‚´ìš©ì„ ë³´ê³  ì¥/ì ˆ/ê´€/ì¡° ì¤‘ ì–´ëŠ ê²ƒì¸ì§€ íŒë³„ (ë…ë¦½ í•¨ìˆ˜)
    
    Args:
        content: í•­ëª©ì˜ ë‚´ìš©
        
    Returns:
        "ì¥", "ì ˆ", "ê´€", "ì¡°" ì¤‘ í•˜ë‚˜
    """
    if not content:
        return "ì¡°"
    
    # ë‚´ìš©ì´ "ì œXì¥", "ì œXì ˆ", "ì œXê´€" íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸ (ì˜ˆì™¸ì  ë„˜ë²„ë§ í¬í•¨)
    if re.match(r'^ì œ\d+ì¥(?:ì˜\d+)?', content.strip()):
        return "ì¥"
    elif re.match(r'^ì œ\d+ì ˆ(?:ì˜\d+)?', content.strip()):
        return "ì ˆ"
    elif re.match(r'^ì œ\d+ê´€(?:ì˜\d+)?', content.strip()):
        return "ê´€"
    else:
        return "ì¡°"

def _combine_structure_titles_standalone(jang: str, jeol: str, gwan: str, original_title: str) -> str:
    """ì¥/ì ˆ/ê´€ ì œëª©ë“¤ì„ ì›ë˜ ì œëª©ê³¼ í•©ì¹˜ê¸° (ë…ë¦½ í•¨ìˆ˜)
    
    Args:
        jang: ì¥ ì œëª©
        jeol: ì ˆ ì œëª©
        gwan: ê´€ ì œëª©
        original_title: ì›ë˜ ì¡°ë¬¸ ì œëª©
        
    Returns:
        í•©ì³ì§„ ì œëª© (ì‰¼í‘œë¡œ êµ¬ë¶„)
    """
    parts = []
    
    if jang:
        parts.append(jang)
    if jeol:
        parts.append(jeol)
    if gwan:
        parts.append(gwan)
    if original_title:
        parts.append(original_title)
    
    return ", ".join(parts)

def _build_structure_hierarchy_standalone(chatbot_data: List[Dict]) -> List[Dict]:
    """ì±—ë´‡ ë°ì´í„°ì—ì„œ ì¥/ì ˆ/ê´€ êµ¬ì¡° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê° ì¡°ë¬¸ì— ë§¤í•‘ (ë…ë¦½ í•¨ìˆ˜)
    
    Args:
        chatbot_data: ì›ë³¸ ì±—ë´‡ í˜•ì‹ ë°ì´í„°
        
    Returns:
        ìƒìœ„ êµ¬ì¡° ì •ë³´ê°€ ì¶”ê°€ëœ ì±—ë´‡ ë°ì´í„°
    """
    current_jang = ""  # í˜„ì¬ ì¥
    current_jeol = ""  # í˜„ì¬ ì ˆ
    current_gwan = ""  # í˜„ì¬ ê´€
    
    result = []
    
    for item in chatbot_data:
        content = item.get("ë‚´ìš©", "")
        title = item.get("ì œëª©", "")
        structure_type = _identify_structure_type_standalone(content)
        
        if structure_type == "ì¥":
            current_jang = _extract_structure_title_standalone(content)
            current_jeol = ""  # ìƒˆë¡œìš´ ì¥ì´ë©´ ì ˆê³¼ ê´€ ì´ˆê¸°í™”
            current_gwan = ""
            continue  # ì¥ í•­ëª©ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
            
        elif structure_type == "ì ˆ":
            current_jeol = _extract_structure_title_standalone(content)
            current_gwan = ""  # ìƒˆë¡œìš´ ì ˆì´ë©´ ê´€ ì´ˆê¸°í™”
            continue  # ì ˆ í•­ëª©ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
            
        elif structure_type == "ê´€":
            current_gwan = _extract_structure_title_standalone(content)
            continue  # ê´€ í•­ëª©ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
            
        else:  # ì¡°ë¬¸ì¸ ê²½ìš°
            # ìƒìœ„ êµ¬ì¡°ë“¤ì„ ì œëª©ì— í•©ì¹˜ê¸°
            enhanced_title = _combine_structure_titles_standalone(
                current_jang, current_jeol, current_gwan, title
            )
            
            enhanced_item = {
                "ì¡°ë²ˆí˜¸": item.get("ì¡°ë²ˆí˜¸", ""),
                "ì œëª©": enhanced_title,
                "ë‚´ìš©": content
            }
            result.append(enhanced_item)
    
    return result

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_structure_enhancement():
    """ê¸°ì¡´ ê´€ì„¸ë²• 3ë‹¨ë¹„êµ JSON íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ìƒìœ„ êµ¬ì¡° ì œëª© í•©ì¹˜ê¸° í…ŒìŠ¤íŠ¸"""
    
    # ê´€ì„¸ë²• 3ë‹¨ë¹„êµ JSON íŒŒì¼ ì½ê¸°
    try:
        with open("ê´€ì„¸ë²•_3ë‹¨ë¹„êµ.json", "r", encoding="utf-8") as f:
            test_data = json.load(f)
            
        print(f"ì›ë³¸ ë°ì´í„° ê°œìˆ˜: {len(test_data)}")
        
        # ìƒìœ„ êµ¬ì¡°ë¥¼ ì¡°ë¬¸ì— ë§¤í•‘
        enhanced_data = _build_structure_hierarchy_standalone(test_data)
        
        print(f"ì²˜ë¦¬ í›„ ë°ì´í„° ê°œìˆ˜: {len(enhanced_data)}")
        print("\n=== ì²˜ë¦¬ ê²°ê³¼ (ì²˜ìŒ 5ê°œ) ===")
        
        for i, item in enumerate(enhanced_data[:5]):
            print(f"{i+1}. ì¡°ë²ˆí˜¸: {item['ì¡°ë²ˆí˜¸']}")
            print(f"   ì œëª©: {item['ì œëª©']}")
            print(f"   ë‚´ìš©: {item['ë‚´ìš©'][:100]}...")
            print()
            
        # ê²°ê³¼ë¥¼ ìƒˆ íŒŒì¼ë¡œ ì €ì¥
        output_filename = "ê´€ì„¸ë²•_3ë‹¨ë¹„êµ_enhanced.json"
        with open(output_filename, "w", encoding="utf-8") as f:
            json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
            
        print(f"âœ… ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def test_api_laws_enhancement():
    """APIë¥¼ í†µí•´ ë²•ë ¹ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ìƒìœ„ êµ¬ì¡° ì œëª© í•©ì¹˜ê¸° í…ŒìŠ¤íŠ¸"""
    
    # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
    import os
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        print("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜µë‹ˆë‹¤.")
    
    api_key = os.getenv('LAW_API_KEY')
    if not api_key:
        print("LAW_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("API í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”:")
        api_key = input("API í‚¤: ").strip()
        if not api_key:
            print("API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
    
    # í…ŒìŠ¤íŠ¸í•  ë²•ë ¹ ëª©ë¡
    laws_to_test = [
        "ì™¸êµ­í™˜ê±°ë˜ë²•",
        "ëŒ€ì™¸ë¬´ì—­ë²•"
    ]
    
    # LawAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    law_api = LawAPI(api_key)
    
    print("=== APIë¥¼ í†µí•œ ë²•ë ¹ ë°ì´í„° ìƒìœ„ êµ¬ì¡° ì œëª© í•©ì¹˜ê¸° í…ŒìŠ¤íŠ¸ ===")
    
    for law_name in laws_to_test:
        print(f"\nğŸ“‹ {law_name} í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        try:
            # 3ë‹¨ ë¹„êµ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìƒìœ„ êµ¬ì¡° ì œëª©ì´ ìë™ìœ¼ë¡œ í•©ì³ì§)
            enhanced_data = law_api.download_three_stage_comparison_as_json(law_name)
            
            if enhanced_data:
                print(f"âœ… {law_name} ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(enhanced_data)}ê°œ ì¡°ë¬¸")
                
                # ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
                print("=== ì²˜ë¦¬ ê²°ê³¼ (ì²˜ìŒ 3ê°œ) ===")
                for i, item in enumerate(enhanced_data[:3]):
                    print(f"{i+1}. ì¡°ë²ˆí˜¸: {item['ì¡°ë²ˆí˜¸']}")
                    print(f"   ì œëª©: {item['ì œëª©']}")
                    print(f"   ë‚´ìš©: {item['ë‚´ìš©'][:80]}...")
                    print()
                
                # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                output_filename = f"{law_name}_3ë‹¨ë¹„êµ_enhanced.json"
                with open(output_filename, "w", encoding="utf-8") as f:
                    json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ“ ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            else:
                print(f"âŒ {law_name} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ {law_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    print("\nğŸ‰ ëª¨ë“  ë²•ë ¹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    print("=== ì¥/ì ˆ/ê´€ êµ¬ì¡° ì œëª© í•©ì¹˜ê¸° í…ŒìŠ¤íŠ¸ ===")
    print("1. ê¸°ì¡´ íŒŒì¼ í…ŒìŠ¤íŠ¸: test_structure_enhancement()")
    print("2. API í…ŒìŠ¤íŠ¸: test_api_laws_enhancement()")
    print()
    
    # ê¸°ì¡´ íŒŒì¼ í…ŒìŠ¤íŠ¸
    print("--- ê¸°ì¡´ ê´€ì„¸ë²• íŒŒì¼ í…ŒìŠ¤íŠ¸ ---")
    test_structure_enhancement()
    
    print("\n--- APIë¥¼ í†µí•œ ì™¸êµ­í™˜ê±°ë˜ë²•, ëŒ€ì™¸ë¬´ì—­ë²• í…ŒìŠ¤íŠ¸ ---")
    test_api_laws_enhancement()